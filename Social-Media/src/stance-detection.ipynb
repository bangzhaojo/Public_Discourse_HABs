{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc13e67-0bc8-4250-9872-575275200970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from getpass import getpass\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "#from wandb.integration.langchain import WandbTracer\n",
    "import wandb\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import argparse\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from time import time,sleep\n",
    "import string\n",
    "import collections\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c58f7b-ec49-4e07-8966-4f1cd37d4927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/lake-erie-reddit_all.csv')\n",
    "texts = data['body'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "842e9ef1-af60-4fd2-86c7-58fed7c8b3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put your api key here\n",
    "API_KEY=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35bf0bc8-6077-40a9-ade7-05483ad61ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1000/4915 [04:59<22:58,  2.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 999 to stance_detection_gpt3.5_1000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 2000/4915 [11:17<15:16,  3.18it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 1999 to stance_detection_gpt3.5_2000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3000/4915 [16:10<12:03,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 2999 to stance_detection_gpt3.5_3000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 4000/4915 [21:05<04:14,  3.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 3999 to stance_detection_gpt3.5_4000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4915/4915 [25:36<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final batch of outputs to stance_detection_gpt3.5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_length = 2048\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    # model_name='gpt-4', \n",
    "    model_name='gpt-3.5-turbo', \n",
    "    openai_api_key=API_KEY, \n",
    "    temperature=0,\n",
    "    max_retries=12, \n",
    "    request_timeout=600)\n",
    "\n",
    "template = \"{text}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "llm_chain = LLMChain(prompt=prompt,llm=llm)\n",
    "\n",
    "outputs = []\n",
    "\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    # designed prompt for stance detection\n",
    "    ppt_template = f\"\"\"Context: Lake Erie and surrounding water bodies are subject to various policies aimed at protecting their water quality, addressing issues from pollution spills to toxic algal blooms. Public opinion on the effectiveness of these policies is crucial for ongoing environmental efforts.\n",
    "\n",
    "Task: Read the following comment carefully. Determine if the comment expresses a belief regarding the effectiveness of current policies aimed at protecting Lake Erie's water quality.\n",
    "\n",
    "If the comment suggests that the policies are making a positive impact, answer 'Yes'.\n",
    "If the comment suggests that the policies are not making a positive impact, answer 'No'.\n",
    "If the comment does not express a stance on the effectiveness of these policies or is unrelated to the policy effectiveness, answer 'None'.\n",
    "Please do not provide any reasoning for your answer. Simply state 'Yes', 'No', or 'None' based on the content of the comment.\n",
    "\n",
    "Comment: {text}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        output = llm_chain.run(ppt_template)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text at index {i}: {e}\")\n",
    "        output = None\n",
    " \n",
    "    outputs.append([text, output])\n",
    "    \n",
    "    if (i + 1) % 1000 == 0:\n",
    "        file_path = f'stance_detection_gpt3.5_{i + 1}.json'\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(outputs, file, indent=4)\n",
    "        print(f'Saved outputs up to index {i} to {file_path}')\n",
    "\n",
    "        \n",
    "final_path = f'stance_detection_gpt3.5.json'\n",
    "with open(final_path, 'w') as file:\n",
    "    json.dump(outputs, file, indent=4)\n",
    "print(f'Saved final batch of outputs to {final_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29791659-2213-4c1c-b85a-f2290984b6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
