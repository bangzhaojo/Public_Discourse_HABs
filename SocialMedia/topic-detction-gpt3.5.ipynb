{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29788ec-ba92-4bb9-99e5-185ccd81b1c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from getpass import getpass\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "#from wandb.integration.langchain import WandbTracer\n",
    "import wandb\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.evaluation.qa import QAEvalChain\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import argparse\n",
    "import json\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "from time import time,sleep\n",
    "import string\n",
    "import collections\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e98dfd4-0996-4cb1-952e-221bd599add0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('rc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ae537a-ae70-49f8-bf03-f3471672f9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0157c1-5bc5-4b6e-b021-8957eef2b86e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That is the thing, I understand these lines ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hmm I guess we all have different views. I wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lake Erie, it's just gross.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I agree that algae is quite normal and this do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ohio has a water border with Canada in Lake Erie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5605</th>\n",
       "      <td>Yet more recent - like half of Lake Erie was c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5606</th>\n",
       "      <td>The water was too poisonous for any life. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5607</th>\n",
       "      <td>Im not saying theyre perfect, there is a lot o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5608</th>\n",
       "      <td>Fair point. The headline and the article itsel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5609</th>\n",
       "      <td>Not for long when the effects of the Trump EPA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5610 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     That is the thing, I understand these lines ar...\n",
       "1     Hmm I guess we all have different views. I wor...\n",
       "2                           Lake Erie, it's just gross.\n",
       "3     I agree that algae is quite normal and this do...\n",
       "4      Ohio has a water border with Canada in Lake Erie\n",
       "...                                                 ...\n",
       "5605  Yet more recent - like half of Lake Erie was c...\n",
       "5606  The water was too poisonous for any life. The ...\n",
       "5607  Im not saying theyre perfect, there is a lot o...\n",
       "5608  Fair point. The headline and the article itsel...\n",
       "5609  Not for long when the effects of the Trump EPA...\n",
       "\n",
       "[5610 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a46120ca-a7a1-4cff-8d7b-f62644635927",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = data['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb0b01d5-58ec-45bf-972c-0dda2041b659",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['That is the thing, I understand these lines are just drawn somewhere and some states/cities can culturally identify with a different area, but the only \"coast\" Ohio has is Lake Erie.',\n",
       " 'Hmm I guess we all have different views. I work for a Planning District Commission (urban and regional city planning) and this is not our general consensus about the James alongside our environmental specialists. Still regarded as having high TMDL levels (total maximum daily load of toxins in a water body) and sediment levels. Just my experience and research. Probably safer than 10 years ago, but not safe enough to swim in without moderate health risk. Personally don’t let me dog go near the water, just the rocks']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6601f9-e80f-470f-bc94-67b2b9732f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_KEY='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09efbc76-4f79-4f78-b5d3-f3df060e5ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1000/5610 [08:13<33:00,  2.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 999 to topic_detection_gpt3.5_1000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 2000/5610 [16:15<31:20,  1.92it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 1999 to topic_detection_gpt3.5_2000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 3000/5610 [24:24<22:43,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 2999 to topic_detection_gpt3.5_3000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 4000/5610 [32:34<13:03,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 3999 to topic_detection_gpt3.5_4000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 5000/5610 [40:41<04:34,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved outputs up to index 4999 to topic_detection_gpt3.5_5000.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5610/5610 [45:41<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final batch of outputs to topic_detection_gpt3.5.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_length = 2048\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    # model_name='gpt-4', \n",
    "    model_name='gpt-3.5-turbo', \n",
    "    openai_api_key=API_KEY, \n",
    "    temperature=0,\n",
    "    max_retries=12, \n",
    "    request_timeout=600)\n",
    "\n",
    "template = \"{text}\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
    "llm_chain = LLMChain(prompt=prompt,llm=llm)\n",
    "\n",
    "outputs = []\n",
    "# for gender,ethnicity,prefix in options:\n",
    "for i, text in enumerate(tqdm(texts)):\n",
    "    ppt_template = f\"\"\"Question: Based on the following comment related to Lake Erie's environmental issues, identify the primary topic it discusses. Select the appropriate topic without providing reasoning.\n",
    "\n",
    "Topics:\n",
    "A. Safety Concern - Relates to pollution or other environmental dangers to people's safety.\n",
    "B. Agricultural Runoff - Discusses farms, nutrients, and agricultural runoff contributing to pollution.\n",
    "C. Policy - Focuses on policies addressing the environmental issues.\n",
    "D. Environmental Knowledge Share - Shares background information or explains the mechanisms behind the issue.\n",
    "E. Purely Negative Feeling - Expresses negative feelings towards the issue without specifying details from the above options.\n",
    "F. Unrelated - The comment is not directly related to any environmtental issues.\n",
    "\n",
    "Comment: {text}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        output = llm_chain.run(ppt_template)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text at index {i}: {e}\")\n",
    "        output = None\n",
    " \n",
    "    outputs.append([text, output])\n",
    "    \n",
    "    if (i + 1) % 1000 == 0:\n",
    "        file_path = f'topic_detection_gpt3.5_{i + 1}.json'\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(outputs, file, indent=4)\n",
    "        print(f'Saved outputs up to index {i} to {file_path}')\n",
    "\n",
    "        \n",
    "final_path = f'topic_detection_gpt3.5.json'\n",
    "with open(final_path, 'w') as file:\n",
    "    json.dump(outputs, file, indent=4)\n",
    "print(f'Saved final batch of outputs to {final_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18e0a5-5af5-4421-8ebd-5551e0b7ecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
